+++
date = "2018-07-12T21:28:14+09:00"
description = "Machine Learning Yearning은 Andrew NG 교수님이 집필중인 온라인 E-Book의 문서입니다. 머신러닝 입문자를 위한 필독서입니다. Machine Learning Yearning을 각 chapter별 번역 문서를 목록입니다. "
title = "Machine Learning Yearning 번역문서 목록"
thumbnailInList = "https://taewanmerepo.github.io/2018/doc/mlyearning/list.png"
thumbnailInPost = "https://taewanmerepo.github.io/2018/doc/mlyearning/00/img000.jpg"
tags = ["ML", "Andrew NG", "E-book"]
categories = []
author = "taewan.kim"
language = ""  
adsense = "true"
+++

## 들어가며

"__Machine Learning Yearning__"은 최근에 Andrew NG 교수님이 온라인 집필 중인 딥러닝 입문서입니다. 전체 56장으로 구성되어 있으며 매주 2-3장씩 메일링으로 공개되고 있습니다. 이 공개 e-book을 번역하는 페이지입니다. 머신 러닝에 대한 실무적이고 직관적인 내용을 정리하고 있습니다. 수식과 복잡한 개념 보다는 실무에서 고민해야 하는 직관적인 내용으로 구성됩니다. 머신러닝 입문자에게 적합한 e-book입니다. 일주일에 1-2개씩 각 chapter별로 문서를 번역하고 업데이트할 예정입니다.  

|일자|ebook draft version 다운로드|
|----|----|
|2018.06.05|[Ng_MLY01_07.pdf](https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/5040470a-5b3b-4564-ab86-eadd55c1583b/Ng_MLY01_07.pdf)|
|2018.05.30|[Ng_MLY01_06.pdf](https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/51925a01-acfb-472e-8eac-4bf105323ff5/Ng_MLY01_06.pdf)|
|2018.04.05|[Ng_MLY01_04.pdf](https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/db5cc9c4-1964-420f-bce6-24835a2aa097/Ng_MLY01_04.pdf)|

### 문서 최신 변경 로그

|일자|ebook draft version 다운로드|
|----|----|
|2018.07.16|14장 번역 추가: [MLY:14. 오류 분석: 새로운 아이디어를 평가하기 위해서 개발셋 데이터를 살펴봐라.](/trans_docs/t_mly_14)|
|2018.07.12|13장 번역 추가: [MLY:13. 첫 시스템 빨리 구축하라. 그 다음 반복하라](/trans_docs/t_mly_13)|
|2018.06.20|12장 번역 추가: [MLY:12. 핵심정리: 개발 세트와 테스트 세트 구성](/trans_docs/t_mly_12)|
|2018.06.20|11장 번역 추가: [MLY:11. 개발 / 테스트 세트 및 평가 지표를 변경 상황](/trans_docs/t_mly_11)|


## 목록

다음은 Machine Learning Yearning의 번역 문서 목록입니다.

### Intro

|#Ch|Original Title|한글 제목|
|----|----|----|
|1| Why Machine Learning Strategy|[MLY:01. 왜 머신러닝 전략인가?](/trans_docs/t_mly_01)|
|2| How to use this book to help your team|[MLY:02. 팀에서 이 책을 활용하는 방법](/trans_docs/t_mly_02)|
|3| Prerequisites and Notation|[MLY:03. 선수학습과 표기법](/trans_docs/t_mly_03)|
|4| Scale drives machine learning progress|[MLY:04. 스케일이 기계학습 발전를 이끈다.](/trans_docs/t_mly_04)|


### Setting up development and test sets

|#Ch|Original Title|한글 제목|
|----|----|----|
|5| Your development and test sets|[MLY:05. 개발 세트과 테스트 세트](/trans_docs/t_mly_05)|
|6| Your dev and test sets should come from <br/>the same distribution|[MLY:06. 개발 세트과 테스트 세트는 동일한 분포를 제공해야 한다.](/trans_docs/t_mly_06)|
|7| How large do the dev/test sets need to be?|[MLY:07. 개발 세트와 테스트 세트의 크기](/trans_docs/t_mly_07)|
|8| Establish a single-number evaluation metric <br/>for your team to optimize|[MLY:08. 최적화에 사용되는 단일 숫자 평가 지표](/trans_docs/t_mly_08)|
|9| Optimizing and satisficing metrics|[MLY:09. 최적화 지표(Optimizing metric)와 만족 지표(satisficing metric)](/trans_docs/t_mly_09)|
|10| Having a dev set and metric speeds up iterations|[MLY:10. 개발 세트와 지표로 반복 속도 향상](/trans_docs/t_mly_10)|
|11| When to change dev/test sets and metrics|[MLY:11. 개발 / 테스트 세트 및 평가 지표를 변경 상황](/trans_docs/t_mly_11)|
|12| Takeaways: Setting up development and test sets|[MLY:12. 핵심정리: 개발 세트와 테스트 세트 구성](/trans_docs/t_mly_12)|


### Basic Error Analysis

|#Ch|Original Title|한글 제목|
|----|----|----|
|13| Build your first system quickly, then iterate|[MLY:13. 첫 시스템 빨리 구축하라. 그 다음 반복하라.](/trans_docs/t_mly_13)|
|14| Error analysis: Look at dev set examples to evaluate ideas|[MLY:14. 오류 분석: 아이디어를 평가하기 위해서 개발셋 데이터를 살펴보라.](/trans_docs/t_mly_14)|
|15| Evaluating multiple ideas in parallel during error analysis||
|16| Cleaning up mislabeled dev and test set examples||
|17| If you have a large dev set, split it into two subsets,<br/>only one of which you look at ||
|18| How big should the Eyeball and Blackbox dev sets be?||
|19| Takeaways: Basic error analysis||


### Bias and Variance

|#Ch|Original Title|한글 제목|
|----|----|----|
|20| Bias and Variance: The two big sources of error||
|21| Examples of Bias and Variance||
|22| Comparing to the optimal error rate||
|23| Addressing Bias and Variance||
|24| Bias vs. Variance tradeoff||
|25| Techniques for reducing avoidable bias||                         
|26| Techniques for reducing Variance||
|27| Error analysis on the training set||

### Learning curves

|Ch|Original Title|한글 제목|
|----|----|----|
|28| Diagnosing bias and variance: Learning curves ||
|29| Plotting training error||
|30| Interpreting learning curves: High bias||
|31| Interpreting learning curves: Other cases||
|32| Plotting learning curves||
|33| Why we compare to human-level performance||
|34| How to define human-level performance||
|35| Surpassing human-level performance||
|36| Why train and test on different distributionsㅍ
|37| Whether to use all your data||
|38| Whether to include inconsistent data||
|39| Weighting data||
|40| Generalizing from the training set to the dev set ||
|41| Addressing Bias and Variance||
|42| Addressing data mismatch||
|43| Artificial data synthesis||
|44| The Optimization Verification test||
|45| General form of Optimization Verification test|
|46| Reinforcement learning example||
|47| The rise of end-to-end learning||
|48| More end-to-end learning examples||
|49| Pros and cons of end-to-end learning||
|50| Learned sub-components||
|51| Directly learning rich outputs||
|52| Error Analysis by Parts||
|53| Beyond supervised learning: What’s next?||
|54| Building a superhero team - Get your teammates to read this||
|55| Big picture||
|56| Credits||


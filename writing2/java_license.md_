+++
date = "2018-10-08T21:28:14+09:00"
description = "Hadoop Core를 중심으로 발전한 빅데이터 기술은 클라우드를 만나면서 빠르게 변화하고 있습니다. Hadoop Core는 향후 On-Premise 빅데이터 기술로 사용되고 클라우드에서의 사용는 점차 줄어들 것으로 예상합니다. 빅데이터 기술의 향후 변화에 대하여 정리합니다."
title = "On-Premise 빅데이터 기술 Hadoop Core"
thumbnailInList = "https://taewanmerepo.github.io/2018/10/murdermemory/list.jpg"
thumbnailInPost = ""
tags = ["hadoop", "spark", "cloud", "bigdata"]
categories = ["java"]
author = "taewan.kim"
language = ""  
jupyter = "false"
adsense = "true"
autoadsense = "true"
+++

{{% notice note %}}
본 문서는 현재 작성중인 문서이며, 공식 배포전입니다. 
{{% /notice %}}

## 하둡 선도 기업의 합병과 하둡의 위상 변화

최근에 빅데이터 업계에 선두 기업인 Cloudera와 Hotonworks가 합병 소식이 화제가 되었습니다. Cloudera는 Hadoop 기술을 선도하는 대표 기업으로 글로벌하게 가장 많은 상용 배포본을 공급하고 있는 업체입니다. Hotonworks도 Cloudera와 같이 Hadoop 기술을 선도하는 대표 기업입니다. 

{{< img src="https://taewanmerepo.github.io/2018/10/hadoopcore/010.jpg"
title="그림 1"
caption="cloudera와 Hotonworks의 주식 총액" >}}


두 회사는 같은 같은 오픈소스 기술을 근간으로 하지만 상당히 다른 성향으로 발전해 왔습니다. Cloudera가 엔터프라이즈 기업에 촛점을 맞춰 배포본을 관리한다면 Hotoworks는 기만한 기술 중심으로 운영하였습니다. Cloudera가 하둡 업계의 RedHat이라면 Hotonwors는 우분투라고 비유할 수 있습니다. 두 기업은 주식 시가 총액, 글로벌 마켓 점유율 등을 비교해보면, Cloudera가 앞서고 있고 Hotonworks가 2위권을 유지하는 모습을 보입니다. 기술적인 측면을 보면 Hotonworks가 업계를 리드하는 모습을 보입니다. 

>|항목|Cloudera|Hotonworks|
|----|----|----|
|설립년도|2009년|2011년|
|Valuation|$4.1B|$1.1B|
|매출액|$100M|$46M|
|Hadoop PMC Member|12명|20명|
|Hadoop Committer|11명|26명|
> - 기업 프로파일 (기준: 2015)
> - 출처: http://talendexpert.com/cloudera-vs-honworks-vs-mapr/

기업은 공통 기술을 기반으로하지만 성향은 상당히 달랐습니다. 하둡 업계에서 두 기업은 다른 경쟁자가 없는 독보적인 투톱이었습니다. 이런 두 빅데어터 선두 기업이 갑자기 합병 소식을 전하고 있습니다. 빅데이터 시장에 어떤 변화가 생겼을까요? 

기업의 데이터센터에 설치되는 데이터 레이크는 당분간 Hadoop Core 기반의 기술셋으로 구축될 것 입니다. 그러나 Cloud에 구축되는 데이터 레이크와 데이터 분석 환경에서는 Hadoop Core는 점차 사라질 것이라고 예상합니다. 

>|Cloud Provider|MapReduce|Spark|YARN|HDFS|Data Lake|빅데이터 서비스|
|----|----|----|----|----|----|----|
|Amaxon AWS|O|O|O|X|S3|EMR|
|MS Azure|O|O|O|O|Azure Blob Storage|Azure HDInsight|
|Oracle Cloud|O|O|O|O|OCI[^1] Object Storage|BDC|
> - 클라우드 프로바이더의 데이터레이크 컴포넌트 구성

[^1]: OCI - Oracle Cloud Infrasturcture의 약자입니다.

현재도 클라우드 프로바이더는 데이터 레이크로 HDFS가 아니라 자체 Object Storage 사용하고 있습니다. AWS의 경우 빅데이터 서비스인 EMR에서 HDFS를 지원하지 않고 있습니다. MS Azure와 오라클 클라우드에는 빅데이터 서비스에서 HDFS를 지원하고는 있지만, 영구 데이터 저장소의 역할이 아닌 하둡 기술을 원할히 사용하기 위한 임시 데이터 저장소 형태로 사용됩니다. 

이렇게 하둡 생태계에 벌어지고 있는 기술의 위상 변화에 대하여 정리해 보겠습니다.

## Hadoop 생태계 급성장: 2010 ~ 2015년 

2010년 부터 빅데이터와 Hadoop은 IT 분야에서 가장 뜨거운 키워드 였습니다. 그리고 가장 각광받고 빠르게 성장하는 기술이고 비지니스 영역이   였습니다. 대용량 데이터를 저장하는 HDFS, 데이터 지역성(Data Locality) 특성을 이용하여 데이터를 분석하는 MapReduce와 분산환경 클러스터의 자원을 관리하는 YARN을 중심으로 견고한 Hadoop 생태계가 만들어 졌습니다. <그림 2 참조>

{{< img src="https://taewanmerepo.github.io/2018/10/hadoopcore/020.png"
title="그림 2"
caption="초기 Hadoop Ecosystem" >}}

<그림 2>와 같이 Hadoop Core(HDFS, MapReduce, Yarn)을 중심으로 여러 기술이 만들어 졌습니다. 하둡 생태계는 <그림 3>과 같이 Hadoop Core를 중심으로 지난 10년 동안 빅뱅의 시기를 보냈습니다. 

{{< img src="https://taewanmerepo.github.io/2018/10/hadoopcore/040.jpg"
title="그림 3"
caption="초기 Hadoop Ecosystem" >}}

지난 10년간의 하둡 생태계의 급격한 팽창과 기술 발전으로 데이터 분석 플랫폼의 개념을 많이 바꿔었습니다. 2018년 현재 온프라미스에서 빅데이터 저장소(Data Lake) 구축은 일반적으로 하둡을 기반으로 구축됩니다. 하둡은 이제 데이터의 저장의 핵심 기술로 자리 매김했습니다. 

### 하둡 생태계의 핵심 Hadoop Core

하둡 생태계는 Hadoop Core를 중심으로 발전했습니다. Hadoop Core의 구성과 역할은 다음과 같습니다. 

>|컴포넌트|역할|
|----|----|
|Hadoop HDFS|- 분산파일시스템<br/>- 데이터를 Object로 분리하여 저장 데이터 크기에 대한 제약이<br/>- 데이터 중복 저장으로 가용성 극대화|2011년|
|Hadoop MapReduce|- 병렬 데이터 처리 프로그램 모델 & 프레임워크<br/>- 대용량 데이터 병렬 처리에 특화되어 있음<br/>- 범용적 프로그램으로 활용하기 어려운 제약이 있음<br/>- File I/O가 큰, 비율적인 제약|
|Hadoop YARN|- 하둡 클러스터 자원관리(Resource Manager)|
> - Hadoop Core 구성 컴포넌트


## MapReduce의 쇄태

하둡 생태계는 Hadoop HDFS에 데이터를 Hadoop MapRduce로 데이터를 처리하는 구조로 발전했습니다. 초기에 하둡은 데이터를 접근하고 조작하기 위해서는 MapReduce를 사용해야 했습니다. Hive와 Pig는 MapRduce를 사용하는 하둡 데이터 처리 기술입니다. MapRduce의 장단점이 그대로 Hive와 Pig에 반영되었습니다. 대용량 데이터를 처리할 수 있다는 장점과 함께 I/O가 너무 많이 발행하여 비효율적인 단점이 문제가 되기 시작했습니다. 
 
### MapReduce를 사용하지 않는 SQL on Hadoop

__SQL on Hadoop__은 HDFS에 저장된 데이터를 SQL로 조회하고 처리하는 기술입니다. 대표적인 __SQL on Hadoop__은 Apache Hive입니다. 앞에서 말씀 드린 것처럼 Hive는 MapRduce를 래핑한 기술입니다. MapReduce는 분산 병렬 처리에 특화된 기술로 대용량 데이터를 병렬처리하기에는 매우 강력합니다. 그러나 데이터 처리 프로세스의 Fault Tolenence를 보장하기 위해서 내부적인 단위 작업마다 파일 I/O과 네트워크 I/O가 발생합니다. 결과적으로 범용적인 프로그램 개발이 어렵고, 지나치게 많은 I/O가 발생한다는 것이 단점이었습니다. 

{{< img src="https://taewanmerepo.github.io/2018/10/hadoopcore/050.jpg"
title="그림 4"
caption="Hadoop MapReduce의 데이터 흐름" >}}

Hive의 이런 문제를 해결하기 위해서 여러가지 SQL on Hadoop이 개발되었습니다. 대표적인 SQL on Hadoop 기술은 Apache Impala, Apache Tajo, Oracle Big Data SQL이 있습니다. 이들 기술의 공통점은 더이상 MapReduce를 사용하지 않는다는 것입니다. 하둡 클러스터의 NameNode의 데이터 메타 정보를 직접 조회하여, 하둡 클러스터의 데이터 노드에 위치하는 데이터 블록을 직접 접근하고 처리하는 자체 데몬을 이용합니다.

{{< img src="https://taewanmerepo.github.io/2018/10/hadoopcore/060.jpg"
title="그림 5"
caption="Apache Impala의 아키텍처와 Impalad 데몬" >}}

Hive의 성능 문제를 개선하기 위해서 만든 SQL on Hadoop 기술인 Apache Impala는 MapReduce를 자체 데몬으로 대체하고 있고, 데이터 처리를 Memory 중심으로하기 때문에 Hive의 성능 문제를 개선하기 위한 기술입니다. Apache Impala는 내부 구성은 <그림 5>와 같습니다. 

Hadoop 초기에는 HDFS의 데이터를 접근하기 위해서는 MapReduce를 사용해야 한다는 제약이 있었지만, 하둡 기술이 성숙해지고 YARN이 지원되면서 하둡 데이터를 직접 접근하고 처리하는 자체 데몬을 사용하거나 YARN 애플리케이션을 만들어 처리하는 방식으로 선호되면서 점차 MapReduce를 직접 사용하는 빈도는 줄어들게 되었습니다. 

### MapReduce의 대안 기술

MapReduce가 각광받은 이유는 map-reduce 패턴으로 병렬 처리를 지원하고, 실행 프로세스는 데이터를 가져오는 것이 아니라 데이터가 존재하는 하둡 클러스터의 데이터 노드에서 mapper와 reducer가 실행되는 Data Locality(데이터 지역성)이 지원된다는 것이었습니다. 그리고 하둡 클러스터가 프로세스를 관리하여 일부 프로세스 장애에 대한 내고장성(Fault Tolerence)이 좋다는 것이었습니다. 

MapReduce의 단점은 map-reduce 패턴이 범용적인 개발 모델로 활용되기 어렵다는 것입니다. 또한 지나차게 File I/O가 많이 발생합니다. 반벅적인 데이터 처리가 발생할 경우 성능 저하가 심각하다는 것입니다.

MapReduce의 대체 기술은 데이터 지역성을 지원하고 File I/O 보다는 메모리 작업을 효과적으로 지원하며, 범용 프로그래밍이 가능한 형태여야 합니다. 

### MapReduce의 대체제 Spark

이런 요건을 갖춘 기술인 Spark이 2012년에 등장했고, Spark은 이미 MapReduce를 대체하였습니다. 

Spark은 인-메모리 기반의 고속 범용 클러스터 컴퓨팅 엔진입니다. 맵리듀스(MapReduce) 모델을 대화형 명령어 쿼리나 스트리밍으로 처리 가능하도록 확장할 수 있습니다. 일괄 처리, 반복 알고리즘, 대화형 쿼리, 스트리밍을 구현하는 범용성을 갖습니다. Spark은 스칼라 언어로 구현되었으며 다양한 언어(파이선, 자바, 스칼라, R)를 지원합니다. 

Spark은 <그림 7>과 같이 기존에 MapReduce가 파일 기반으로 데이터를 분산하는 문제를 메모리 기반으로 대체하였습니다. 이러한 특징으로 반복적인 데이터 처리를 유리한 구조를 갖고 있습니다.

{{< img src="https://taewanmerepo.github.io/2018/10/hadoopcore/070.jpg"
title="그림 8"
caption="MapReduce와 Spark의 데이터 관리 체계" >}}

Apache Spark은 SQL, 스트리밍, 머신러닝, 그래프를 지원합니다. 이제 Apache Spark은 프레임워크가 아닌 Spark Stack으로 자리잡았습니다.

{{< img src="https://taewanmerepo.github.io/2018/10/hadoopcore/080.jpg"
title="그림 9"
caption="Spark Stack" >}}

## Cloud 빅데이터

Cloud에서 빅데이터 분석 환경을 구축할 수 있습니다. 이때 첫번째 고려 대상은 Hadoop HDFS의 역할입니다. 클라우드에서 서버는 물리적 서버가 아닌 VM(Virtual Machine)입니다. VM

### 







 





<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>통계 on taewan.kim 블로그</title>
    <link>http://taewan.kim/tags/%ED%86%B5%EA%B3%84/</link>
    <description>Recent content in 통계 on taewan.kim 블로그</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 18 Aug 2018 20:28:14 +0900</lastBuildDate>
    
	<atom:link href="http://taewan.kim/tags/%ED%86%B5%EA%B3%84/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[til]처음시작하는 머신러닝 11장</title>
      <link>http://taewan.kim/til/first_ml_05/</link>
      <pubDate>Sat, 18 Aug 2018 20:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/first_ml_05/</guid>
      <description> 11장 문서 분석  문서 분류 시스템 토픽 모델 시스템 품사 분석 시스템 고유명사 태깅 시스템 단어 임베딩 학습  </description>
    </item>
    
    <item>
      <title>[til]처음시작하는 머신러닝 6-9장</title>
      <link>http://taewan.kim/til/first_ml_04/</link>
      <pubDate>Sat, 18 Aug 2018 20:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/first_ml_04/</guid>
      <description>7장 추천 유사도  Jaccard similarity coefficient: 두 집합의 원소의 유사도  개념  두 집합 A, B $\frac{|A \cap B|}{|A \cup B|} $ 두 집합의 교집합 원소 수와 합집합 원소 수의 비율  특징  희소 벡터로 구성된 데이터에 대한 집단 비교에 유용함   Cosine Similarity: 방향  $sim(X, Y) = \frac{X \cdot Y}{||X||\ ||Y||}$  X, Y 벡터   Edit Distance: 작업 연산 수  편집 연산의 수  Insert(삽입) Delete(삭제) Substitution(대체) transposition(전치)  예  슈퍼맨 1, 슈퍼맨 2: 2 (1삭제, 2삽입)    Recommendation 내용 기반 추천  장점  사용자 정보 없이 추천 가능 이해하기 쉬움  단점  독특한 아이템 추천이 어려움 신규 사용자 추천 어려움   CF 추천  사용자 기반 협업 필터링  다른 사람의 구매 이력을 이용하여 추천  상품 기반 협업 필터링</description>
    </item>
    
    <item>
      <title>[til]처음시작하는 머신러닝 4-5장</title>
      <link>http://taewan.kim/til/first_ml_03/</link>
      <pubDate>Fri, 17 Aug 2018 20:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/first_ml_03/</guid>
      <description>4. 군집화 Euclidean Distance $$ d(x, y) = \sqrt{\sum^n_{i=1}(x_i-y_i)^2} = ||X-Y|| $$
$$ Squared Euclidean Distance = \sum^n_{i=1}(x_i-y_i)^2=||X-Y||^2_2 $$
군집화 유형  중심기반 군집화  k-means clustering k-medians clustering k-modes clustering  계층적 군집화 밀도기반 군집화  중심기반 군집화  K개의 임의의 포인트 선정 각 데이터와 K개 포인트의 거리 계산 각 데이터를 K개의 포인트에 할당 K개 포인트를 중심점으로 이동 2-4를 반복  계층적 군집화  최상의 클러스터: 모든 데이터 포함 최하위 클러스터: 1개의 데이터 포함 클러스터 방식  하향식 분할적 클러스터화  전체를 1개의 클러스터로 지정 중심점 지정 중심점에서 가장 먼 데이터 확인 중심점과 먼 거리 데이터를 기준으로 거리 계산 중심점과 먼거리에 데이터 할당 클러스터 별로 2-5반복  상향식 집괴적 클러스터화  1개의 1개의 클러스터로 지정 거리가 가까운 2개를 뭉쳐 클러스터화 거리가 가까운 2개 클러스터 뭉침  가까운 거리 기준 먼거리 기준 평균거리 기준  1개가 남을때 까지 반복    밀도 기반 군집화  유형  평균 이동 군집화 DBSCAN: Density-based spatial clustering of applications with noise  용어  core point: 반경 Epsilon안에 일정 개수 이상의 데이터가 존재하는 데이터 border point: 중심 포인트보다 적지만, 중심 포인트로 부터 반경 Epsilon안에 존재하는 데이터 noise point: core point도 border point도 아닌 데이터     유사도 계산  타입  Minkoski Distance: 벡터 공간의 두 점간 거리 Mahalanobis distance: 점간 분포를 고려한 거리   minkowski distance  $$ d(X, Y) = \sqrt[p]{\sum^m_{i=1}|x_i-y_i|^p} $$</description>
    </item>
    
    <item>
      <title>[til]처음시작하는 머신러닝 2-3장</title>
      <link>http://taewan.kim/til/first_ml_02/</link>
      <pubDate>Wed, 15 Aug 2018 20:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/first_ml_02/</guid>
      <description>2장. 주요 개념  Topic  Model Loss Function Optimization Model Evaluation   Model  모델이란 데이터에 대한 가정(Hypothesis)의 총합
 통계학에서는 Hypothesis를 Belief라고 함  단순(간단) 모델
 데이터의 단순성을 가정 이해하기 쉬운 결과 학습 용이 복잡한 데이터를 학습하기 어려움(표현력 제약)  복잡한 모델
 가정이 없음 이해하기 어려운 결과 학습이 복잡 새로운 데이터에 대한 성능이 떨어짐  결정 트리
 트리의 분기마다 1가지 조건으로 분기 마지막 리프노드에 결과 하당   구조적 모델  순차모델  Sequence Model  RNN: Recurrent neural net, 순환신경망  수식: $h_t = w_0 + w1h(t-1) + w_2x_t $  CRF: Conditional Random Field, 조건부 랜덤 필드   그래프모델  Markov Random Field  문서의 문법구조 이미지 픽셀 사이의 관계를 그래프로 표현    좋은 모델?</description>
    </item>
    
    <item>
      <title>[til]처음시작하는 머신러닝 1장</title>
      <link>http://taewan.kim/til/first_ml_01/</link>
      <pubDate>Mon, 13 Aug 2018 20:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/first_ml_01/</guid>
      <description>머신러닝 정의  머신러닝이란? 데이터를 이용하여 명시적으로 정의하지 않은 패턴을 컴퓨터로 학습하여 결과를 만들어내는 학문 분야
 1959, 아서 사무엘(Arthur Lee Samuel)   머신러닝 구성 요소  Data Pattern Recognition Computing  머시러닝 관련 학문  수학 - 행렬 - 선형대수: 행렬분해 - 확률: 조건부 확률 통계학: 데이터에서 패턴을 찾아내는 학문 - 정규 분포, 가우스분포, 상관관계 컴퓨터 공학  고집적 연산 병렬 연산 프로그래밍   과거와 현재  1950년: 얼런튜닝의 튜링테스트 제안 1957년: Percetron 제안 1990 - 2010: 통계적 머신러닝 2010 ~ : 빅데이터 2013 ~ : 딥러닝 - GPU 발전 - 데이터 증가 - 알고리즘 발전</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#8: 확률 변수, 확률 분포, 이산확률 분포 </title>
      <link>http://taewan.kim/til/basic_statistics_09/</link>
      <pubDate>Mon, 06 Aug 2018 20:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_09/</guid>
      <description>01. 확률 변수, 확률 분포 확률변수, 확률 분포는 함수다.
  Sample Space는 시행에서 얻어지는 모든 결과의 집합. Sample Space의 모든 원소를 실수로 대응하는 함수: 확률 변수 확률 변수로 얻어진 실수를 확률값으로 변화하는 함수: 확률 분포 확률 변수와 확률 분포를 이용하여 시행의 결과를 실수로 변환할 수 있고, 발생 확률로 변환할 수 있다.   그림 1: 확률 변수와 확률 분포는 함수다     최종 확률분포표로 제시  02.</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#8: 사건의 독립과 종속 </title>
      <link>http://taewan.kim/til/basic_statistics_08/</link>
      <pubDate>Fri, 03 Aug 2018 23:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_08/</guid>
      <description>01. 사건의 독립과 종속  예제  10개의 제비뽑기가 있음, 당첨제베는 2개, 철수와 영희 순서로 제비뽑기 진행 복원추출: 제비를 뽑으면 다시 주머니에 추가 비복원추출: 뽑힌 제비는 재사용하지 않음, 제거     복원 추출      철수의 확률 $\Longrightarrow$ 영희가 당청될 확률     철수의 당첨 사건 $\frac{2}{10}$ $\Longrightarrow$ $\frac{2}{10}$   철수의 비당첨 사건 $\frac{8}{10}$ $\Longrightarrow$ $\frac{2}{10}$      철수의 당첨 여부는 영희의 당첨 사건 확률은 변하지 않음 철수의 당첨 사건은 영희의 당첨 사건에 영향을 미치지 않음    비복원 추출      철수의 확률 $\Longrightarrow$ 영희가 당청될 확률     철수의 당첨 사건 $\frac{2}{10}$ $\Longrightarrow$ $\frac{1}{9}$   철수의 비당첨 사건 $\frac{8}{10}$ $\Longrightarrow$ $\frac{2}{10}$      철수의 당첨 여부에 따라서 영희의 당첨 활률이 변함 철수의 당첨 사건은 영희의 당첨 사건에 영향을 미침  독립과 종속  종속: 사건이 2개 있을 때, 한 사건이 다른 사건에 영향을 주는 것  두 사건이 종속되었다라고 표현 비복원  독립: 사건이 2개 있을 때, 한 사건이 다른 사건에 영향을 주지 않는 것  두 사건이 됙립되었다라고 표현 복원   수식으로 살펴본 종속  $$ P(B|A) \neq P(B|A^c) $$</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#7: 확률 개념 </title>
      <link>http://taewan.kim/til/basic_statistics_07/</link>
      <pubDate>Thu, 02 Aug 2018 23:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_07/</guid>
      <description>01. 확률의 개념 용어정리  Trial: 시행이란 동일한 조건에서 여러번 반복할 수 있고 그 결과가 우연에 의해서 결정되는 관찰이나 실험  예제: 주사위 던지기  Sample Space: 표본 공간  Trial(시행)의 결과들의 집합 예제 - 동전을 던지는 실험에서 표본 공간은 {앞면, 뒷면} - 6면 주사위를 던지는 실험에서 표본 공간은 {1, 2, 3, 4, 5, 6}  Event: 사건  표본 공간의 부분 집합  fundamental event: 근원 사건  원소의 갯수가 한 개인 사건 표본 공간이 한 원소로 이루어 집합  합사건: 두 사건 A와 B의 합집합으로 표현할 수 있는 사건  $A \cup B$ 예제: 4의 약수가 나오거나 또는 홀수가 나오는 사건 {1,2, 3, 4}  곱사건: 두 사건 A와 B의 교집합으로 표현할 수 있는 사건  $A \cap B$ 예제: 4의 약수 그리고 혹수 =&amp;gt; {1}  여사건: 여집합으로 표현되는 사건  $A^c$ 예제: 4의 약수가 나오지 않는 사건  배반사건: A와 B 사전의 교집합니 공집합인 사건  $A \cap B= \emptyset$   수학적 확률  수학적 확률은 근원 사건이 일어날 가능성이 모두 같을 때, 수학적 확률을 계산할 수 있다.</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#6: 이항정리 </title>
      <link>http://taewan.kim/til/basic_statistics_06/</link>
      <pubDate>Thu, 02 Aug 2018 11:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_06/</guid>
      <description>01. 이항정리  이항정리는?
 $(a+b)^n$이 전개되는 방식을 정리 항이 두 개인 거듭제곱의 전개 방식을 소개  $(a+b)(a+b)=a^2+ab+ba+b^2$
 $(a+b)(a+b)(a+b)$ : 8개의 항이 존재함 (2X2X2)
 aaa aab aba baa abb bab bba bbb $a^3+3a^2+3ab^2+b^3$ = $a^3$: $_3C_0$=&amp;gt; 3개 중에서 b를 한개도 뽑지 않는 경우의 수 = $3a^2b$: $_3C_1$=&amp;gt; 3개 중에서 b를 한 개 뽑을 경우의 수 = $3ab^2$: $_3C_2$=&amp;gt; 3개 중에서 b를 두 개 뽑을 경우의 수 = #b^3$: $_3C_3$=&amp;gt; 3개 중에서 b를 세 개 뽑을 경우의 수  $(a+b)(a+b)(a+b)(a+b)$ : 8개의 항이 존재함 (2X2X2)</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#5: 자연수 분할&amp;집합분할 </title>
      <link>http://taewan.kim/til/basic_statistics_05/</link>
      <pubDate>Wed, 01 Aug 2018 23:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_05/</guid>
      <description>01. 자연수 분할  생각해 볼 거리1
 5를 2개의 자연수 합으로 표현하는 방법  {1, 4}, {2, 3}, {3, 2}, {1, 4} : 순서를 고려할 필요 없음 2개  5를 3개의 자연수 합으로 표현  {3, 1, 1}, {2, 2, 1}   n = n_1+n_2+n_3+&amp;hellip;&amp;hellip;+n_k
 n을 k개의 수로 분할할 수 있음 n&amp;gt;=n_1&amp;gt;=n_2&amp;gt;=n_3&amp;gt;=&amp;hellip;..&amp;gt;=n_k 1 &amp;lt;= k &amp;lt;= n example  5 k=1 ==&amp;gt; {5} k=5 ==&amp;gt; {1,1,1,1,1}   자연수 n을 n보다 작거나 같은 k개의 자연수의 합으로 순서를 고려하지 않고 표현한 것은 자연수의 분할 이라고 한다.</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#4: 조합 </title>
      <link>http://taewan.kim/til/basic_statistics_04/</link>
      <pubDate>Mon, 30 Jul 2018 23:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_04/</guid>
      <description>1. 조합  순열(Permutation): 순서있게 나열하는 방법의 수  $_nP_r$: n개중에서 r개를 뽑아서 순서 있게 나열한 수 $\frac{n!}{(n-r)!}$  조합(Combination): 순서를 고려하지 않고 선택하는 방법의 수  순열을 순서를 고려한 경우의 수임 조합은 순서를 고려하지 않음 순열의 객수에 선택한 갯수의 경우의 수로 나워서 순열의 중복을 제거 순열의 순서를 제거 =&amp;gt; $_nC_r = \frac{_nP_r}{r!}$    예제  ABCDE 중에서 2개를 뽑아서 순서있게 나열하는 것  $_5P_2$  ABCDE 중에서 2개를 조합  순서를 고려하지 않음 선택만 함 5개 중에서 2개를 선택하는 것 $_5C_2$ = $\frac{_5P_2}{2!</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#3: 중복순열 </title>
      <link>http://taewan.kim/til/basic_statistics_03/</link>
      <pubDate>Sun, 29 Jul 2018 21:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_03/</guid>
      <description>1. 같은것이 존재하는 순열 같은 것이 있는 순열  ABCD 나열: 4! AACD의 나열  ABCD에서 B를 A로 치환한것 ABCD와 BACD는 AACD가 됨 2가지 경우의 수는 1개가 됨 두 가지가 같은 것이므로 제외: 4!/2! = 12  AAAD의 나열  ABCD의 ABC를 A로 치환 ABCD, ACBD, BACD, BCAD, CABD, CBAD는 AAAD가 됨 6개가 1개로 됨 4!/3!=4  AABB이 나열  ABCD에서 C=A로 D=B로 치환 4!/(2!2!)= 6   일부의 순서가 결정된 순열  문제1: ABCDE가 존재한다.</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#2: 원순열 </title>
      <link>http://taewan.kim/til/basic_statistics_02/</link>
      <pubDate>Sat, 28 Jul 2018 01:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_02/</guid>
      <description>1. 원순열  순열: 일렬로 순서있게 나열하는 방법, 처음과 끝이 존재 원순열: 처음과 끝이 없는 상태로 순서있게 나열하는 방법, 원위에 나열하는 개념  처음과 끝이 없다 한방향으로 요소의 나열 순서가 같으면 같은 것으로 간주    처음과 끝이 없는 순열에 처음과 끝을 만드는 방법  첫번째 요소를 고정하여 기준으로 처음과 끝을 만듦 첫번째 요소는 모든 요소가 위치할 수 있음 전체 순열의 수에서 첫 번째 요소에 올 수 있는 요소 수를 나누면 원수열의 갯수가 됨 첫번째 요소는 기준을 정하는 역할을 담당할 뿐 경우의 수에 미치는 영향이 없어짐    $$ 원순열= /frac{n!</description>
    </item>
    
    <item>
      <title>[til]기초 확률&amp;통계#1: 경우의수 &amp; 순열 </title>
      <link>http://taewan.kim/til/basic_statistics_01/</link>
      <pubDate>Fri, 27 Jul 2018 21:28:14 +0900</pubDate>
      
      <guid>http://taewan.kim/til/basic_statistics_01/</guid>
      <description>1. 경우의 수  합의 법칙: 동시에 일어나지 않는 사건 (각 사건의 경우의 수 합) 곡의 법칙: 동시에 일어나는 혹은 연달아 일어나는 두 사건(가 사건의 경우의 수 곱)  Case1 - 합의 법칙 사례  문제: 1-10 카드 10장 중에서 2장을 선택하여, 두 합이 7의 배수가 되는 경우의 수   풀이  두 장의 카드 합의 크기 범위: $3&amp;lt;= A+B &amp;lt;= 19$ 가능한 7의 배수: {7, 14} 두 카드를 선택할 때 순서는 중요하지 않음 두 카드의 합 7: (1, 6) (2, 5) (3, 4) 두 카드의 합 14: (4, 10) (5, 9) (6, 8) 7이 되는 사건과 14가 되는 사건은 동시에 발생할 수 없음 합의 법칙 적용 경우의 수 = 두 카드의 합 7의 경우의 수 + 두 카드의 합 14의 경우의 수 = 6   Case2 - 합의 법칙 사례  문제: 자연수 x와 y가 있다.</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Autograd on taewan.kim 블로그</title>
    <link>http://taewan.kim/tags/autograd/</link>
    <description>Recent content in Autograd on taewan.kim 블로그</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Mar 2018 03:05:14 +0900</lastBuildDate>
    
	<atom:link href="http://taewan.kim/tags/autograd/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Neural Networks</title>
      <link>http://taewan.kim/trans/pytorch/tutorial/blits/03_neural_networks/</link>
      <pubDate>Tue, 27 Mar 2018 03:05:14 +0900</pubDate>
      
      <guid>http://taewan.kim/trans/pytorch/tutorial/blits/03_neural_networks/</guid>
      <description>ML 문서 번역 &amp;gt; PyTorch Tutorial &amp;gt; PyTorch와 함께하는 딥러닝: 60분 리뷰 &amp;gt; 신경망
  원문: http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html 원문 제목: Neural Networks   torch.nn 패키지를 사용하여 신경망을 만들 수 있습니다.
지금까지 autograd에 대하여 살펴보았습니다. nn 패지지는 autograd를 사용하여 모델을 정의하고 미분합니다. nn.Module은 여러 레이어와 forward(input) 메서드를 포함합니다. 이 forward 메서드는 output을 반환합니다.
다음 이미지는 디지틀 사진을 분류하는 신경망입니다.
convnet1
위 신경망은 단순한 feed-forward 네트워크입니다. 이 신경망은 입력된 데이터를 순차적으로 여러 레이어에 데이터를 공급합니다.</description>
    </item>
    
    <item>
      <title>Autograd: 미분 자동화</title>
      <link>http://taewan.kim/torchtrans/tutorial/blits/autograd/</link>
      <pubDate>Sun, 18 Mar 2018 03:05:14 +0900</pubDate>
      
      <guid>http://taewan.kim/torchtrans/tutorial/blits/autograd/</guid>
      <description>원문: http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html 원문 제목: Autograd: automatic differentiation?  PyTorch의 모든 신경 네트워크의 중심에는 autograd 패키지가 있습니다. 먼저 autograd에 대하여 간략히 살펴 보겠습니다. 그러나서 첫 번째 신경망을 훈련해 볼 것 입니다.
autograd 패키지는 오든 텐서 연산에 대해 미분 자동화 기능을 제공합니다. 실행 정의(define-by-run) 프레임웍입니다. 실행 정의란 역전파는 코드가 실행되는 방식에 이해 정이됨을 의미합니다. 모든 반복마다 달라질 수 있습니다.
몇 가지 예로 좀 더 간단한 용어를 살펴보겠습니다.
Variable Gradients NumPy 배열을 Torch 텐서로 변환 import numpy as np a = np.</description>
    </item>
    
    <item>
      <title>Autograd: 미분 자동화</title>
      <link>http://taewan.kim/trans/pytorch/tutorial/blits/02_autograd/</link>
      <pubDate>Tue, 27 Feb 2018 03:05:14 +0900</pubDate>
      
      <guid>http://taewan.kim/trans/pytorch/tutorial/blits/02_autograd/</guid>
      <description>ML 문서 번역 &amp;gt; PyTorch Tutorial &amp;gt; PyTorch와 함께하는 딥러닝: 60분 리뷰 &amp;gt; Autograd: 미분 자동화
  원문: http://http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html 원문 제목: Autograd: automatic differentiation   PyTorch으로 만든 모든 신경망의 중심에는 autograd 패키지가 있습니다. 먼저 autograd 패키지를 간략히 살펴보겠습니다. 그리구 다음 문서에서 첫 번째 신경망을 훈련해 보겠습니다.
autograd 패키지는 Tensor로 수행한 모든 연산에 대하여 자동-미분(Autimatic differentiation) 기능을 제공합니다. autograd는 실행 시점에 정의되는(define-by-run) 프레임워크입니다. 이것은 코드가 어떻게 실행되는가에 따라서 역전파(backprop)가 정의됨을 의미합니다.</description>
    </item>
    
  </channel>
</rss>